---
title: Contribute to the INCLUDE benchmark
description: Help us create diverse benchmarks to ensure fair representation in LLMs!
date: 2025-01-09T16:00:00.000+00:00
lang: en
duration: 1min
cover: "https://github.com/somosnlp/assets/raw/main/images/patrocinios/INCLUDE_post.png"
author: Angelika Romanou
bio: PhD Candidate at Ã‰cole Polytechnique FÃ©dÃ©rale de Lausanne (EPFL)
website: https://agromanou.github.io/
twitter: https://x.com/agromanou
linkedin: https://www.linkedin.com/in/angelika-romanou-67067057/
---

TL;DR: We are looking for multiple-choice tests in any language to add to the multicultural INCLUDE benchmark. Fill out the [form](https://forms.gle/9VbDMSHvhqSQbtL56) now!

<div class="flex justify-center">
    <img src="https://github.com/somosnlp/assets/raw/main/images/patrocinios/INCLUDE_post.png" alt="INCLUDE" width="400">
</div>

It is often said that large language models (LLMs) are developing increasingly advanced multilingual capabilities, but in which languages exactly? In the case of languages spoken in several countries, which varieties of the language are being considered? If we aim for LLMs to be multilingual and multicultural, we need to ensure that the entire global community is represented in the datasets. Change starts by creating diverse evaluation benchmarks that allow us to measure the current state and make progress toward truly inclusive LLMs.

[INCLUDE](https://arxiv.org/abs/2411.19799) is a multilingual LLM evaluation benchmark with a focus on culture. The first version, published in December 2024, included 42 languages. We are looking for tests in all languages to extend this benchmark and make it more representative!

## âœ… We are looking for tests in any language!

Requirement:
- Answers must be available

Preferred tests:
- Multiple-choice tests
- Tests related to a country's or region's culture (e.g., history, literature)

Examples:
- University exams (including entrance exams)
- School exams  
- Professional certification exams (medicine, psychology, law, etc.)  
- Language tests  
- Driving license tests  
- Questions from shows like "Who Wants to Be a Millionaire?"  
- Questions from games like Trivial Pursuit  
- Self-assessment tests in textbooks 

Tests can be either online or in physical textbooks or documents.

## ðŸ’¡ Contribute to AI speaking your language!

- **How can I help?** Send us links to tests via this [form](https://forms.gle/9VbDMSHvhqSQbtL56), we will take care of processing them.  
- **Can I participate more actively in this project?** If you are interested, for example, in becoming a language lead, collecting tests in your country, assisting with processing the exams, or analyzing the results, indicate so in the last question of the form and we will contact you.  
- **How is active collaboration rewarded?** People who process more than 300 questions will be eligible to become co-authors of papers related to the project.
- **What will you do with the tests?** We will process and combine them to make a huge multilingual exam for LLMs, which will be public and available to the whole community.

## ðŸ“š Useful Links

- [First INCLUDE paper](https://arxiv.org/abs/2411.19799)  
- [Current dataset on Hugging Face](https://huggingface.co/datasets/CohereForAI/include-base-44)  
- [Form to share exams](https://forms.gle/9VbDMSHvhqSQbtL56)  

## ðŸš€ Meet the team

Angelika Romanou, Antoine Bosselut, Negar Foroutan and Anna Sotnikova from Ã‰cole Polytechnique FÃ©dÃ©rale de Lausanne (EPFL), MarÃ­a Grandury from SomosNLP, Jabez Magomere from the University of Oxford, and Shamsuddeen H. Muhammad from Imperial College London.

This project is funded by EPFL, Swiss National AI Institute, and Meta. All the data gathered will be publicly available under an open-source license.

## ðŸ‘‹ Contact

- If you indicate in the form that you are interested in actively participating, we will contact you via email!
- For any question, feel free to contact angelika.romanou@epfl.ch and maria.grandury@somosnlp.org

