---
title: "Reto Principal #HackathonSomosNLP 2025: Alineamiento de LLMs y VLLMs"
description: C√≥mo participar en este reto y ayudar a mejorar el conocimiento cultural de los modelos de lenguaje y visi√≥n-lenguaje
lang: es
cover: https://somosnlp.github.io/assets/images/eventos/250401_hackathon_sinfecha.jpg
---

## üéØ Objetivo del reto

- Elige una de las siguientes opciones:
    - A. Alinea un **modelo de lenguaje** (LLM) para generar texto de manera culturalmente adecuada
    - B. Adapta un **modelo multimodal visi√≥n-lenguaje** (VLLM) para generar descripciones de im√°genes teniendo en cuenta el contexto cultural
- En espa√±ol, portugu√©s o cualquier lengua de la Pen√≠nsula Ib√©rica o LATAM
- Adapta de un modelo ya existente (no pre-entrenes uno desde cero), recomendamos tomar de base modelos en torno a 7B (e.g. [Salamandra](https://huggingface.co/BSC-LT/salamandra-7b-instruct), [Mistral](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3) y [Gemma](https://huggingface.co/google/gemma-3-4b-it))
- ¬°Genera el dataset con ayuda de 500 USD en cr√©ditos de la API de Cohere! Recomendamos filtrar y extender el dataset de preferencias v0 generado en com√∫n en la Arena: [somosnlp-hackathon-2025/dataset-preferencias-dpo-v0](https://huggingface.co/datasets/somosnlp-hackathon-2025/dataset-preferencias-dpo-v0)
- Entrena tu modelo directamente en JupyterLab en el hub de Hugging Face, ¬°tenemos GPUs patrocinadas por ü§ó! 
- Sube el modelo(s) junto con todos los notebooks utilizados a hf.co/somosnlp-hackathon-2025
- Escribe la [Model Card](https://huggingface.co/spaces/huggingface/Model_Cards_Writing_Tool), incluye enlaces al dataset y los notebooks utilizados (e.g. preprocesamiento, entrenamiento)

---

## Gu√≠a

### ‚úÖ Preparaci√≥n

<details>
<summary>Requisitos por equipo</summary>

1. Contribuir 100 prompts **de calidad** al dataset de [preferencias](https://somosnlp.org/hackathon/retos/preferencias)
2. Responder 200 preguntas del dataset de evaluaci√≥n ([BLEND](https://somosnlp.org/hackathon/retos/blend))
3. Pedir los 500 USD cr√©ditos de la API de Cohere (tras completar los puntos 1 y 2, mencionar a @mariagrandury en el canal de vuestro equipo para instrucciones)
4. Crear en la organizaci√≥n hf.co/somosnlp-hackathon-2025 un Space con la plantilla de [jupyterlab](https://huggingface.co/docs/hub/spaces-sdks-docker-jupyter)
5. Completar el [formulario de registro](https://forms.gle/mLKEURUXGiNhq31T9)

</details>

### üìö Dataset

Los datos son lo m√°s importante en el desarrollo de un modelo y tambi√©n le daremos mayor importancia a la hora de evaluar los proyectos üëÄ

- Genera un dataset para tu proyecto:
    - Toma como versi√≥n inicial para tu dataset el generado en com√∫n en la Arena: [somosnlp-hackathon-2025/dataset-preferencias-dpo-v0](https://huggingface.co/datasets/somosnlp-hackathon-2025/dataset-preferencias-dpo-v0)
    - Aprovecha los 500 USD de cr√©ditos de la API de Cohere que tiene cada equipo para filtrarlo, mejorarlo y extenderlo con m√°s prompts y respuestas espec√≠ficamente dise√±ados para tu caso de uso
    - Ten en cuenta que trat√°ndose de temas culturales, es muy importante que todo lo que se genere sint√©ticamente sea revisado por una persona (pod√©is utilizar [Argilla](https://huggingface.co/docs/hub/en/datasets-argilla))
- Sube el dataset a hf.co/somosnlp-hackathon-2025 e itera
- Sube al repo del dataset todos los notebooks y scripts utilizados para generar el dataset y procesarlo
    - Si prefieres crear un repo en GitHub con todo el c√≥digo, puedes hacerlo, no olvides de incluir un enlace en la Dataset Card
- Cumplimenta **bien** la Dataset Card
    - "Dataset Card" es el nombre de la documentaci√≥n en los datasets de Hugging Face, es el README.md del repositorio de los datasets
    - OJO: Se tiene en cuenta para la evaluaci√≥n del proyecto
    - Incluye en la introducci√≥n la motivaci√≥n del proyecto e impacto
    - Detalla el proceso de generaci√≥n y procesamiento, incluye las librer√≠as utilizadas y menciona las pruebas hechas, incluye los enlaces al c√≥digo
    - Especifica la licencia: a poder ser `apache-2.0`, si no, explica por qu√©
    - Eval√∫a los sesgos del dataset, si est√° balanceado, qu√© variedades del lenguaje u opiniones representa, etc.

C√≥mo nombrar los datasets:
- El nombre del dataset con los (m√≠nimo 100) prompts que enviasteis al LLM Arena debe contener `prompt`. Por ejemplo: `normas_culturales_colombia_prompts`
- El nombre de los datasets de preferencias deben contener el nombre del algoritmo principal para el que se pueden utilizar (`dpo` o `kto`). Por ejemplo: `normas_culturales_colombia_dpo`
- Si el dataset es multimodal, debe contener `image`. Por ejemplo: `utensilios_ecuador_images_kto`

### ‚öôÔ∏è Modelo

1. Crear en la organizaci√≥n hf.co/somosnlp-hackathon-2025 un Space con la plantilla de [JupyterLab](https://huggingface.co/docs/hub/spaces-sdks-docker-jupyter)
2. El equipo de Hugging Face le asignar√° un grant de una *L40S* al Space
    - Configura el tiempo de "auto-sleep" a 5 minutos para asegurar un uso responsable üå± 
3. Dise√±a el notebook de entrenamiento
    - Guarda el modelo resultante directamente en hf.co/somosnlp-hackathon-2025
    - Utiliza la librer√≠a CodeCarbon para evaluar el impacto clim√°tico
4. Haz pruebas con modelos peque√±os y subconjuntos del dataset para verificar que el c√≥digo es correcto y no encontrar bugs despu√©s de varias horas de entrenamiento.
5. Lanza el entrenamiento, revisa los resultados e itera
    - Puedes probar e.g. diferentes algoritmos o modelos base
    - No hace falta que crees un repo diferente para cada modelo, si haces push a un mismo repo, el modelo actualizado se guardar√° como un nuevo commit (al que puedes enlazar desde la Model Card si quieres)
6. **Descarga los notebooks de procesamiento del dataset y entrenamiento del modelo, s√∫belos al repo del modelo** (MUY IMPORTANTE) y elimina el Space de JupyterLab
7. Cumplimenta **bien** la Model Card
    - "Model Card" es el nombre de la documentaci√≥n en los modelos de Hugging Face, es el README.md del repositorio de los modelos
    - OJO: Se tiene en cuenta para la evaluaci√≥n del proyecto
    - Recomendaci√≥n: Vete describiendo las pruebas seg√∫n las haces, as√≠ como el proceso de mejora del dataset y entrenamiento del modelos
    - Incluye en la introducci√≥n la motivaci√≥n del proyecto e impacto
    - Detalla el proceso de entrenamiento, incluye las librer√≠as utilizadas y menciona las pruebas hechas, incluye los enlaces al c√≥digo
    - Especifica la licencia: a poder ser `apache-2.0`, si no, explica por qu√©
    - Eval√∫a los sesgos del modelo
    - Eval√∫a el impacto ambiental

---

## Recursos

A continuaci√≥n compartimos un mont√≥n de recursos para que pod√°is desarrollar proyectos de gran calidad. Los recursos marcados con ‚≠ê corresponden a charlas y talleres impartidas durante el hackathon y pensados espec√≠ficamente para ayudaros en esta edici√≥n.

### üìö Dataset

La API de Cohere:
- ‚≠ê [Taller pr√°ctico: C√≥mo utilizar la API de Cohere](https://www.youtube.com/watch?v=S_Wky6D9Nf0&list=PLTA-KAy8nxaDHyJyPlrDMCkwTsJZpMNK6) impartido por Alejandro Rodriguez, Research Engineer en Cohere. Utilizad los modelos de Cohere para limpiar y extender vuestro dataset.

Creaci√≥n de datasets:
- ‚≠ê [Red Teaming para modelos de lenguaje](https://www.youtube.com/watch?v=pGOXE4rrO9M&list=PLTA-KAy8nxaDHyJyPlrDMCkwTsJZpMNK6), impartido por Luis Vasquez, del equipo de Reinforcement Learning, Alignment & Red Teaming del Barcelona Supercomputing Center.
- ‚≠ê [MuSeD: Creaci√≥n de un corpus multimodal en espa√±ol para la detecci√≥n de sexismo en v√≠deos de redes sociales](https://www.youtube.com/watch?v=w1ikWRaBQd0&list=PLTA-KAy8nxaDHyJyPlrDMCkwTsJZpMNK6), impartida por Laura De Grazia de la Universitat de Barcelona.
- [C√≥mo anotar corpus ling√º√≠sticos para entrenar LLMs](https://www.youtube.com/watch?v=d6vrflcIY-g&list=PLTA-KAy8nxaASMwEUWkkTfMaDxWBxn-8J), impartida por Marta Guerrero @IIC, co-creadora de 3 de los corpus que forman La Leaderboard.
- [Distilabel y Argilla, herramientas para crear modelos como Notus](https://www.youtube.com/watch?v=riM3pgV4m_I&list=PLTA-KAy8nxaASMwEUWkkTfMaDxWBxn-8J) impartido por Gabriel Mart√≠n, MLE @Argilla (notebook disponible).

Inspiraci√≥n:
- ‚≠ê [Describing and interpreting interaction using cultural scripts](https://www.youtube.com/watch?v=jLh9Wyn7qcI&list=PLTA-KAy8nxaDHyJyPlrDMCkwTsJZpMNK6), charla impartida en ingl√©s por Lauren Sadow de la Aarhus University.
- ‚≠ê [Expresando incertidumbre en tareas multiling√ºes](https://www.youtube.com/watch?v=TC9tOEyPqy8&list=PLTA-KAy8nxaDHyJyPlrDMCkwTsJZpMNK6) impartida por Selene B√°ez, investigadora postdoctoral en la University of Zurich.
- [√âtica ambiental en IA: construyendo narrativas sostenibles en espa√±ol](https://www.youtube.com/watch?v=MJLdrXz6bSE&list=PLTA-KAy8nxaASMwEUWkkTfMaDxWBxn-8J), charla impartida por Jorge Vallego, Project Lead @H4rmony. Os puede servir para darle un enfoque eco-consciente a vuestro dataset.

### ‚öôÔ∏è Modelo

Creaci√≥n del Space de entrenamiento:
- [Docs: Jupyterlab en Spaces](https://huggingface.co/docs/hub/en/spaces-sdks-docker-jupyter#jupyterlab-on-spaces), donde pod√©is correr vuestros notebooks como siempre. OJO a perder el almacenamiento al reiniciar el Space, ¬°guardad los notebooks!
<!--
- [Docs: AutoTrain (ingl√©s)](https://huggingface.co/docs/autotrain/llm_finetuning), os animamos a probar esta plataforma no-code de Hugging Face. Vamos a traducir esta secci√≥n de la documentaci√≥n, avisadnos si necesit√°is ayuda para comprenderla.
- [Tutorial: AutoTrain + spacerunner (ingl√©s)](https://huggingface.co/blog/stefan-it/autotrain-flair-mobie), con esta combinaci√≥n pod√©is correr scripts en AutoTrain.
-->

Alineamiento de LLMs:
- ‚≠ê [Taller pr√°ctico: Alineaci√≥n de LLMs usando Aprendizaje por Refuerzo](https://www.youtube.com/watch?v=wI6yjbed_1Q&list=PLTA-KAy8nxaDHyJyPlrDMCkwTsJZpMNK6) impartido por Luis Vasquez, del equipo de Reinforcement Learning, Alignment & Red Teaming del Barcelona Supercomputing Center.

Modelos multimodales:
- ‚≠ê [Charla: C√≥mo hacer un Modelo Visi√≥n-Lenguaje eficiente](https://www.youtube.com/watch?v=PjOXDCe_3kg&list=PLTA-KAy8nxaDHyJyPlrDMCkwTsJZpMNK6) impartida por Andr√©s Marafioti, ML Engineer en Hugging Face y creador de SmolVLM.
- ‚≠ê [Charla: Instruction Tuning para Razonamiento Secuencial Multimodal](https://www.youtube.com/watch?v=xiAfa6rafRs&list=PLTA-KAy8nxaDHyJyPlrDMCkwTsJZpMNK6) impartida por Danae Sanchez investigadora postdoctoral en la Universidad de Copenhagen.

Fine-tuning de LLMs:
- [Taller pr√°ctico: El impacto de la calidad de los datos en un FT de LLMs](https://www.youtube.com/watch?v=hPq5NG8kA8w&list=PLTA-KAy8nxaASMwEUWkkTfMaDxWBxn-8J), impartido tambi√©n por Manu Romero, creador de +500 modelos del Hub de Hugging Face.
- [Taller pr√°ctico: Fine-tuning de grandes modelos de lenguaje](https://somosnlp.org/hackathon-2023/fine-tuning-llms) impartido por Manu Romero, creador de +500 modelos del Hub de Hugging Face.
- [Taller + AMA sobre entrenamiento de LLMs](https://www.youtube.com/playlist?list=PLTA-KAy8nxaASMwEUWkkTfMaDxWBxn-8J) con Alejandro Vaca, fundador de LenguajeNaturalAI.
- Notebooks de `unsloth` para entrenar m√°s r√°pido (en ingl√©s, si necesit√°is que los traduzcamos avisadnos):
[Gemma FT en dataset de instrucciones estilo Alpaca](https://colab.research.google.com/drive/10NbwlsRChbma1v55m8LAPYG15uQv6HLo) y
[Hacer RLAIF via DPO sobre Zephir](https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP).

Impacto clim√°tico:
- Para evaluar la huella de carbono del entrenamiento de tu modelo puedes utilizar herramientas como [Code Carbon](https://codecarbon.io) (mejor, integrada en ü§ó Transformers) o [ML CO2 Impact](https://mlco2.github.io/impact).
- Te recomendamos este [v√≠deo](https://www.youtube.com/watch?v=ftWlj4FBHTg) de motivaci√≥n, este [art√≠culo](https://huggingface.co/blog/carbon-emissions-on-the-hub) del blog de HF y la secci√≥n de la [documentaci√≥n](https://huggingface.co/docs/hub/model-cards-co2) de ü§ó Transformers que trata este tema.

###¬†üìù Documentaci√≥n

- [Docs: c√≥mo escribir una buena Dataset Card](https://huggingface.co/docs/datasets/dataset_card): es la documentaci√≥n oficial de Hugging Face, incluye una plantilla y un par de buenos ejemplos.
- [Docs: c√≥mo escribir una Model Card](https://huggingface.co/docs/hub/model-cards): gu√≠a oficial de Hugging Face, incluye un enlace al Space para crearla autom√°ticamente y una explicaci√≥n de cada secci√≥n.
- [Space: Model Card Creator](https://huggingface.co/spaces/huggingface/Model_Cards_Writing_Tool), Space que os gu√≠a en la creaci√≥n de vuestra model card.
- [Detecci√≥n y mitigaci√≥n de sesgos en modelos de lenguaje](https://somosnlp.org/hackathon-2023/evaluacion-de-sesgos), charla impartida por Mar√≠a Grandury, fundadora de SomosNLP.

<center style="margin-top:40px;"><a href="https://somosnlp.org/hackathon/retos" target="_blank" style="background-color:gray; color:white; padding:10px 20px; text-decoration:none; border-radius:5px;">Volver a los retos</a></center>
