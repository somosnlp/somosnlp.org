---
title: Selecci√≥n de art√≠culos II (Dic 2024)
description: Selecci√≥n de art√≠culos relevantes para la comunidad hispanohablante.
date: 2024-12-3T12:00:00.000+00:00
lang: es
duration: 4min
cover: https://somosnlp.github.io/assets/images/blog/seleccion_articulos.png
author: Gonzalo Mart√≠nez, PhD
bio: Investigador de PLN @UC3M
scholar: https://scholar.google.com/citations?user=FF6Yw5QAAAAJ
---

¬°Hola de nuevo, bienvenidos a la segunda edici√≥n de res√∫menes de art√≠culos de SomosNLP! 

Sabemos que es casi imposible mantenerse al d√≠a con todas las novedades en el mundo del NLP en espa√±ol, as√≠ que aqu√≠ estamos para compartir contigo los papers m√°s interesantes. Si tienes alguna sugerencia o quieres que comentemos tu trabajo, ¬°escr√≠benos a info@somosnlp.com!

En esta edici√≥n nos hemos centrado en los art√≠culos sobre espa√±ol de la conferencia EMNLP, ¬°una de las m√°s importantes de NLP en todo el mundo!


<div class="flex justify-center">
    <img src="https://github.com/somosnlp/assets/raw/main/images/blog/seleccion_articulos_laura_rdgz.png" alt="Selecci√≥n de art√≠culos" width="400">
</div>

## üîç Simplificaci√≥n L√©xica en Espa√±ol y Catal√°n: Dos nuevos Corpus

*Lexical Complexity Prediction and Lexical Simplification for Catalan and Spanish: Resource Creation, Quality Assessment, and Ethical Considerationss*

Paper: https://aclanthology.org/2024.tsar-1.9/

Los autores presentan dos nuevos conjuntos de datos para la simplificaci√≥n l√©xica y la predicci√≥n de complejidad l√©xica en espa√±ol y catal√°n.  Esta tarea consiste en remplazar las m√°s palabras complejas de un texto por otras m√°s simples y f√°ciles de entender. As√≠ personas con problemas cognitivos o que est√°n aprendiendo el idioma, pueden acceder a √©l y disfrutarlo. Por desgracia, no existen muchos recursos en espa√±ol ni en catal√°n, en comparaci√≥n a los que existen en ingl√©s. Gracias a estos autores se podr√° avanzar en los estudios de esta √°rea en nuestros idiomas.  El datasets en espa√±ol consta de 625 palabras en 210 contextos distintos obtenidas de textos educativos sobre finanzas, mientras que el dataset en catal√°n tiene 475 palabras objetivo en 160 contextos de noticias educativas. 

## üíü M√°s All√° de las Emociones B√°sicas: Identificaci√≥n de Estados Afectivos

*MASIVE: Open-Ended Affective State Identification in English and Spanish*

Paper: https://aclanthology.org/2024.emnlp-main.1139/

El An√°lisis de sentimientos se ha centrado en emociones b√°sicas como tristeza, alegr√≠a, etc. Sin embargo, en la vida real utilizamos emociones m√°s espec√≠ficas y hasta coloquiales: cagado, flipando, tusa. Para estudiarlo, los autores presentan MASSIVE, un corpus de estas emociones en ingl√©s y Espa√±ol. Este ha sido creado a partir de publicaciones de Reddit. El conjunto de datos en espa√±ol tiene una gran variedad de etiquetas de estados afectivos, incluidos t√©rminos espec√≠ficos de dialectos regionales del espa√±ol, siendo un recurso muy valioso para estudiar variaciones dialectales en la expresi√≥n emocional.

## üì∞ Traducci√≥n de Asturiano: Caltengamos les nueses lling√ºes!

*Enhaced Apertium System: Translation into Low-Resource Languages of Spain Spanish‚ÄìAsturian*

Paper: https://aclanthology.org/2024.wmt-1.84/ 

Este art√≠culo trata sobre las nuevas mejoras a Eslema, un sistema de traducci√≥n m√°quina Espa√±ol-Asturiano basada en reglas Apertium. Detallan las dificultades de trabajar con el asturiano, una lengua de bajos recursos que carece de reconocimiento oficial en Espa√±a. Esta falta de reconocimiento se traduce en una financiaci√≥n y recursos limitados para el desarrollo de tecnolog√≠as ling√º√≠sticas, creando barreras para la presencia digital del asturiano y los esfuerzos de preservaci√≥n ling√º√≠stica. El art√≠culo tambi√©n discute el problema de las m√©tricas de evaluaci√≥n para lenguas de bajos recursos como el asturiano. Los autores argumentan que m√©tricas est√°ndar como BLEU, que dependen de coincidencias literales palabra por palabra, no siempre son apropiadas para evaluar la calidad de las traducciones en lenguas con datos limitados.

## ü©∫ Reconocimiento de Entidades M√©dicas

*Few-shot clinical entity recognition in English, French and Spanish: masked language models outperform generative model prompting*

Paper: https://aclanthology.org/2024.findings-emnlp.400/

Este art√≠culo investiga el rendimiento de varios modelos de lenguaje en tareas de Reconocimiento de Entidades Nombradas (NER) en textos cl√≠nicos en ingl√©s, franc√©s y espa√±ol. El NER implica identificar y clasificar entidades nombradas, como condiciones m√©dicas, s√≠ntomas o tratamientos, dentro del texto. Esta tarea es crucial para construir sistemas de extracci√≥n de informaci√≥n cl√≠nica, permitiendo el an√°lisis automatizado de registros de pacientes y apoyando la toma de decisiones cl√≠nicas.

## ü§ñ Creatividad Artificial: Comparando LLMs con Escritores Humanos

*Pron vs Prompt: Can Large Language Models already Challenge a World-Class Fiction Author at Creative Text Writing?*

Paper: https://aclanthology.org/2024.emnlp-main.1096/

¬øPod√≠a ganar ChatGPT a un experimentado novelista? ü§î Este art√≠culo examina las capacidades de escritura creativa de los LLMs compar√°ndolas con el reconocido novelista espa√±ol Patricio Pron.  Se enfocan en una tarea espec√≠fica de escritura creativa: generar sinopsis cortas para t√≠tulos de pel√≠culas imaginarias. De este modo pudieron hacer una comparaci√≥n controlada de la creatividad humana y la m√°quina, en elementos como originalidad, atractivo y estructura narrativa. Los resultados muestran que GPT-4, aunque es capaz de generar textos coherentes y gramaticalmente correctos, no alcanza las habilidades de escritura creativa de Pron.

## üìö Corpus Espa√±ol para Traducci√≥n Autom√°tica: Diversidad Dialectal en SEED

*Spanish Corpus and Provenance with Computer-Aided Translation for the WMT24 OLDI Shared Task*

Paper: https://aclanthology.org/2024.wmt-1.50/ 

Este art√≠culo detalla la creaci√≥n de un nuevo corpus en espa√±ol para el conjunto de datos SEED, un masivo conjunto de datos multiling√ºe para entrenar modelos de traducci√≥n autom√°tica. Los autores se enfocan en las variedades de espa√±ol latinoamericano para alinearse con la cobertura ling√º√≠stica del benchmark FLORES+, un conjunto de datos clave para lenguas de bajos recursos. Este enfoque resalta la importancia de representar la diversidad dialectal en los recursos ling√º√≠sticos, alej√°ndose de un enfoque √∫nico para el espa√±ol.

¬°Hasta la pr√≥xima!
