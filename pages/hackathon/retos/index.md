---
title: "Retos #HackathonSomosNLP 2025"
description: Vamos a impulsar la creaci√≥n de modelos de lenguaje alineados con la cultura de los pa√≠ses de LATAM y la Pen√≠nsula Ib√©rica.
lang: es
cover: https://somosnlp.github.io/assets/images/eventos/250401_hackathon_sinfecha.jpg
---

El hackathon de este a√±o se centra en la creaci√≥n de recursos que permitan la evaluaci√≥n y el alineamiento de modelos de lenguaje con la cultura de los pa√≠ses de LATAM y la Pen√≠nsula Ib√©rica.

El hackathon consta de un reto principal y varios mini retos con los que tambi√©n pod√©is acumular puntos para los premios finales y ganar premios extra. La puntuaci√≥n m√°xima total es de 10 puntos.

Antes de comenzar:
- √önete al servidor de [Discord de SomosNLP](https://discord.com/invite/my8w7JUxZR)
- Crea una cuenta en [Hugging Face](https://huggingface.co/join)
- Rellena el [formulario de registro](https://forms.gle/bDaBC7XV3iu2trj59)
- √önete a la [organizaci√≥n de Hugging Face](https://huggingface.co/organizations/somosnlp-hackathon-2025/share/BMALwncoPyZLRdPuzwugnsDzXHsbLnjjGD)
- [Crea o √∫nete a un equipo](https://discord.com/channels/938134488670675055/1082369575666073611), crear un hilo en el canal #encuentra-equipo es la manera de registrar tu equipo para el hackathon

Si tienes cualquier duda:
- Revisa el canal [#anuncios](https://discord.com/channels/938134488670675055/944255490748207115), recomendamos activar las notificaciones del canal, publicamos m√°ximo 1 vez al d√≠a
- Preg√∫ntanos en el canal [#pide-ayuda](https://discord.com/channels/938134488670675055/1051997272356966430) de Discord para que todo el mundo pueda beneficiarse de la respuesta
- Los eventos los anunciamos en el canal [#eventos](https://discord.com/channels/938134488670675055/939934987581534228) y los a√±adimos al [calendario](https://calendar.google.com/calendar/u/0?cid=ZWM3MGZhODIzNmYyNzBlMTYwYzFiMjdhNDgzZWMyMjA1ZjQwYzUyN2E5N2MwZTJhZmY0OTcwZDZmZjBkYzQyMEBncm91cC5jYWxlbmRhci5nb29nbGUuY29t)

¬°A por ello! üöÄ


## ‚ú® Mini retos

### ‚úÖ Ex√°menes (INCLUDE)

Busca ex√°menes de opci√≥n m√∫ltiple de tu pa√≠s para evaluar el conocimiento de los LLMs. Prioriza ex√°menes en lenguas distintas al espa√±ol y/o centrados en temas culturales (e.g. historia, literatura). Utilizaremos estas preguntas y respuestas para extender el benchmark abierto INCLUDE.

*9 de abril - 21 de abril | m√°x 1 pto*


[¬°Participa ya!](https://docs.google.com/spreadsheets/d/1QLPQ7gah9yzG3-1BPIw5Jp994Rz8L_yZT8obgWH8S2Y)

<details>
<summary>M√°s informaci√≥n</summary>

Gu√≠as y material de apoyo: [aqu√≠](https://somosnlp.org/hackathon/retos/include)
- Protocolo de recolecci√≥n de ex√°menes
- Recomendaciones para encontrar ex√°menes
- Gu√≠a para extraer preguntas y respuestas de ex√°menes

Incentivos:
- 100 por equipo = 0.5 ptos y premio valorado en 50 USD
- 200 por equipo = 1 pto y premio valorado en 100 USD
- 300 por persona = invitaci√≥n al Slack del proyecto global y co-autor√≠a en el paper de INCLUDE v2

Much√≠simas gracias a:
- EPFL: Premios y organizaci√≥n del equipo global
- El equipo: Mar√≠a Grandury y Angelika Romanou

</details>

### üëÄ Estereotipos

Comparte y eval√∫a estereotipos para ayudar a mitigar sesgos de los LLMs.

*9 de abril - 7 de mayo | m√°x 1 pto*

[¬°Participa ya!](https://ediadev.ngrok.app/)

<details>
<summary>M√°s informaci√≥n</summary>

Gu√≠as y material de apoyo: [aqu√≠](https://somosnlp.org/hackathon/retos/estereotipos)
- V√≠deo explicativo de la herramienta
- Gu√≠a escrita para utilizar la herramienta

Incentivos:
- 100 por equipo = 1 pto
- Tendr√©is acceso a los datos recolectados para alinear vuestro LLM

Much√≠simas gracias a:
- El equipo: Luciana Benotti, Marcos Javier G√≥mez, Guido Ivetta, Sof√≠a Martinelli Nair Carolina Mazzeo, Beatriz Busaniche, Emilia Echeveste
y Pietro Palombini 

</details>

### ‚ùì Preguntas culturales (BLEND)

Responde preguntas sobre tu pa√≠s para evaluar el conocimiento cultural de LLMs. Utilizaremos estas respuestas para extender el benchmark abierto BLEND.

*14 de abril - 7 de mayo | m√°x 2 ptos*

¬°Participa ya! 

<details>
<summary>M√°s informaci√≥n</summary>

Gu√≠as y material de apoyo:
- Gu√≠a para responder preguntas
- Gu√≠a para validar respuestas
- Gu√≠a para proponer nuevas preguntas

Incentivos:
- 200 por equipo = acceso a los 500 USD de la API Cohere para el reto principal
- 50 por persona = co-autor√≠a en el paper

Much√≠simas gracias a:
- CENIA: Almacenamiento de los datos en los espacios de anotaci√≥n
- El equipo: Eugenio Herrera, Sebasti√°n Cifuentes, Clemente, Diana Galv√°n y Mar√≠a Grandury

</details>

## üî• Reto principal

### üìö Dataset de preferencias (LLM Arena)

Dise√±a prompts que eval√∫en la adecuaci√≥n cultural con tu pa√≠s y elige la mejor respuesta en un LLM Arena. Los prompts y las respuestas ser√°n recolectados y compartidos con todos los equipos participantes como dataset de preferencias v0 para la fase de alineamiento. Para este reto tendr√°s acceso a un LLM Arena con 5 modelos de gran tama√±o o propietarios.

*14 de abril - 21 de abril | m√°x 3 ptos*

¬°Participa ya!
<details>
<summary>M√°s informaci√≥n</summary>

Gu√≠as y material de apoyo:
- Gu√≠a para dise√±ar buenos prompts

Incentivos:
- 100 por equipo = acceso a los 500 USD de la API de Cohere para el reto principal
- 200 por equipo = 2 ptos
- Suma hasta 3 ptos a la puntuaci√≥n total de tu equipo

Much√≠simas gracias a:
- CENIA: Cr√©ditos API para los LLMs de la Arena
- El equipo: Gonzalo Fuentes, Diana Galv√°n, Eugenio Herrera, Sebasti√°n Cifuentes, Clemente y Mar√≠a Grandury

</details>

### ‚öôÔ∏è Opci√≥n A: Alineamiento de LLMs

Procesa, filtra y extiende el dataset de preferencias v0 adapt√°ndolo a tu caso de uso. Util√≠zalo para alinear un LLM utilizando t√©cnicas de entrenamiento optimizado y alineamiento como LoRA, cuantizaci√≥n y optimizaci√≥n directa de preferencias (DPO). Para este reto cada equipo tendr√° acceso a 500 USD de la API de Cohere y una GPU L40S de Hugging Face.

*21 de abril - 5 de mayo | m√°x 3 ptos*

<details>
<summary>M√°s informaci√≥n</summary>

Gu√≠as y material de apoyo:
- Notebook de ejemplo para alinear un LLM con DPO

Incentivos:
- Suma hasta 3 ptos a la puntuaci√≥n total de tu equipo

Much√≠simas gracias a:
- Cohere: Cr√©ditos API por un valor de 500 USD para cada equipo
- Hugging Face: GPUs L40S para cada equipo (L40S = 8 vCPU, 62 GB RAM, 48 GB VRAM)

</details>

### üé® Opci√≥n B: Proyecto multimodal cultural

Crea un modelo multimodal que genere descripciones de im√°genes teniendo en cuenta el contexto. Para este reto cada equipo tendr√° acceso a 500 USD de la API de Cohere y una GPU L40S de Hugging Face.

*21 de abril - 5 de mayo | m√°x 3 ptos*

<details>
<summary>M√°s informaci√≥n</summary>

Gu√≠as y material de apoyo:
- Notebook de ejemplo para entrenar un modelo de generaci√≥n de descripciones de im√°genes

Incentivos:
- Suma hasta 3 ptos a la puntuaci√≥n total de tu equipo

Much√≠simas gracias a:
- Cohere: Cr√©ditos API por un valor de 500 USD para cada equipo
- Hugging Face: GPUs L40S para cada equipo (L40S = 8 vCPU, 62 GB RAM, 48 GB VRAM)

</details>

### üé• Creaci√≥n de una demo

Crea una demo de tu proyecto en un Space de HuggingFace para que todo el mundo pueda ver tu trabajo.

*21 de abril - 5 de mayo | m√°x 0.5 ptos*

<details>
<summary>M√°s informaci√≥n</summary>

Gu√≠as y material de apoyo:
- C√≥digo de ejemplo para crear una demo en Hugging Face

Incentivos:
- Suma hasta 0.5 ptos a la puntuaci√≥n total de tu equipo
- Mejores 2 o 3 demos = extensi√≥n del tiempo de ZeroGPU

Much√≠simas gracias a:
- Hugging Face: ZeroGPU para las  demos

</details>

### üé• V√≠deo 5‚Äô presentando el proyecto

Graba un v√≠deo 5 minutos presentando tu proyecto.

*7 de mayo | m√°x 0.5 ptos*

<details>
<summary>M√°s informaci√≥n</summary>

Gu√≠as y material de apoyo:
- Recomendaciones para crear una presentaci√≥n

Incentivos:
- Suma hasta 0.5 ptos a la puntuaci√≥n total de tu equipo
- Requerido por Mistral para dar los cr√©ditos al equipo ganador

</details>

### üìù Opcional: escritura de un paper

Con la ayuda de doctorandos, profesores y profesoras, escribe un paper presentando tu proyecto y m√°ndalo al workshop de LatinX in NLP de NeurIPS, una de las conferencias m√°s importantes del campo.

<details>
<summary>M√°s informaci√≥n</summary>

Incentivos:
- Gana experiencia de investigaci√≥n
- Si tu paper es aceptado, ¬°tendr√°s la oportunidad de viajar a Vancouver a presentarlo!

Much√≠simas gracias a:
- LatinX in AI: Mentor√≠as para escribir papers

</details>

## üìÖ Eventos

#### Confidently wrong: expresando incertidumbre en tareas multilinguales | Selene Baez, Postdoc @ University of Zurich

Si bien la fluidez y la coherencia de los Modelos de Lenguaje (LLM) en la generaci√≥n de texto han mejorado significativamente, su capacidad para generar expresiones adecuadas de incertidumbre sigue siendo limitada. Mediante una tarea de Q&A multiling√ºe a libro cerrado y GPT-3.5, exploramos la precisi√≥n con la que los LLM se calibran y expresan certeza en una variedad de idiomas, incluyendo entornos con bajos recursos.

[¬°Grabaci√≥n disponible!](https://www.youtube.com/watch?v=TC9tOEyPqy8&list=PLTA-KAy8nxaDHyJyPlrDMCkwTsJZpMNK6)


#### Red Teaming para Modelos de Lenguaje | Luis Vasquez, Research Engineer @Barcelona Supercomputing Center

Breve introducci√≥n al Red Teaming para Modelos de Lenguaje: definici√≥n, estrategias comunes y recursos.

[¬°Grabaci√≥n disponible!](https://www.youtube.com/watch?v=pGOXE4rrO9M&list=PLTA-KAy8nxaDHyJyPlrDMCkwTsJZpMNK6)

