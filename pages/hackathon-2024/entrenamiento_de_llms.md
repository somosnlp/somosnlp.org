---
title: "Taller + AMA: Entrenamiento de LLMs"
date: 2023-03-18T18:00:00.000+00:00
time:
duration: 1h45
cover: https://somosnlp.github.io/assets/images/eventos/240318_alejandro_vaca.jpg
author: Alejandro Vaca Serrano
twitter: 
linkedin: https://www.linkedin.com/in/alejandro-vaca-serrano/
website: https://lenguajenatural.ai
github: 
bio: Ganador de varios premios, como el 1er premio del Cajamar UniversityHack 2020, el Premio a Mejor Data Scientist del Hackaton de SpainAI 2021 gracias a sus dos 1os premios y un 3er premio. Lideró al equipo ganador del Hackaton SomosNLP22, con el proyecto BioMedIA, que también presentó en NAACL2022, obteniendo el Premio a Mejor Presentación de Póster. Lideró el desarrollo de LLMs en el IIC desde el 2019, con el desarrollo de los modelos de comprensión de texto RigoBERTa y RigoBERTa-2, así como el modelo de chat RigoChat. Recientemente ha montado su propia empresa LenguajeNatural.AI.
---

<EventSummary
    description="En esta charla aprenderás cómo entrenar LLMs del Estado del Arte con las técnicas más recientes y avanzadas en hardware limitado. Se cubrirá desde la adaptación a idioma / dominio hasta el alineamiento de estos modelos con las preferencias del usuario, pasando por el aprendizaje de instrucciones conversacional. Además, podrás preguntarle a Alejandro tooodas tus dudas sobre entrenamiento de LLMs."
    poster="https://somosnlp.github.io/assets/images/eventos/240318_alejandro_vaca.jpg"
    video="https://www.youtube.com/embed/458UWBlBdtI"
    slides=""
    notebook=""
    tema=2
    nivel=4
    name="Alejandro Vaca Serrano"
    website="https://lenguajenatural.ai"
    twitter=""
    linkedin="https://www.linkedin.com/in/alejandro-vaca-serrano/"
    github=""
    bio="Ganador de varios premios, como el 1er premio del Cajamar UniversityHack 2020, el Premio a Mejor Data Scientist del Hackaton de SpainAI 2021 gracias a sus dos 1os premios y un 3er premio. Lideró al equipo ganador del Hackaton SomosNLP22, con el proyecto BioMedIA, que también presentó en NAACL2022, obteniendo el Premio a Mejor Presentación de Póster. Lideró el desarrollo de LLMs en el IIC desde el 2019, con el desarrollo de los modelos de comprensión de texto RigoBERTa y RigoBERTa-2, así como el modelo de chat RigoChat. Recientemente ha montado su propia empresa LenguajeNatural.AI."
/>

## ¿Qué vas a aprender al asistir a esta charla?

- Cómo entrenar LLMs con técnicas del estado del arte en hardware limitado.
- Los trucos más importantes para obtener un buen rendimiento en un modelo de instrucciones / conversacional.
- Cómo alinear LLMs en base a las preferencias del usuario con las técnicas más recientes de alineamiento: más allá de RLHF.
- Cómo ahorrar en recursos en el entrenamiento de estos LLMs.
- Cómo usar una librería que facilita los puntos 1-4 para hacer más fácil y accesible la puesta a punto de LLMs para casos de uso concretos.

## Charlas relacionadas
