---
title: Bases de Datos
description: Lista de bases de datos open-source en espa침ol. 
cover: "https://somosnlp.github.io/assets/images/undraw_education_edited.svg" 
---

<ResourceItem
    name="Catalonia Independence Corpus"
    :tags="['clasificaci칩n de sentimientos']"
    description="Esta base de datos contiene dos corpus en espa침ol y catal치n que contienen mensajes de Twitter anotados para la detecci칩n de opiniones. Cada corpus est치 anotado con tres posturas: 'against', 'favor' y 'neutral' (a favor, en contra, neutral) respecto a la independencia de Catalu침a."
    website
    github="https://github.com/ixa-ehu/catalonia-independence-corpus"
    paper="https://www.aclweb.org/anthology/2020.lrec-1.171/"
    hf_dataset_name="catalonia_independence" 
    hf_contributor_handle="lewtun"
/>

---

<ResourceItem
    name="eHealth-KD"
    :tags="['NER (Named Entity Recognition)']"
    description="Base de datos del challenge eHealth-KD de IberLEF 2020. Est치 dise침ado para la identificaci칩n de entidades y relaciones sem치nticas en documentos sanitarios espa침oles."
    website="https://knowledge-learning.github.io/ehealthkd-2020/"
    github="https://github.com/knowledge-learning/ehealthkd-2020"
    paper="http://ceur-ws.org/Vol-2664/eHealth-KD_overview.pdf"
    hf_dataset_name="ehealth_kd" 
    hf_contributor_handle="mariagrandury"
/>
 
 ---

<ResourceItem
    name="HEAD-QA"
    :tags="['preguntas de opci칩n m칰ltiple']"
    description="HEAD-QA es un conjunto de datos de preguntas de opci칩n m칰ltiple sobre medicina. Las preguntas proceden de ex치menes para acceder a un puesto en el sistema sanitario espa침ol y suponen un reto incluso para humanos altamente especializados."
    website="https://aghie.github.io/head-qa/"
    github="https://github.com/aghie/head-qa"
    paper="https://www.aclweb.org/anthology/P19-1092/"
    hf_dataset_name="head_qa" 
    hf_contributor_handle="mariagrandury"
/>

---

<ResourceItem
    name="Large Spanish Corpus"
    :tags="['modelado del lenguaje', 'pre-entrenamiento']"
    description="El Large Spanish Corpus es una compilaci칩n de 15 corpus espa침oles sin etiquetar que abarcan desde la Wikipedia hasta las notas del Parlamento Europeo. Cada configuraci칩n contiene los datos correspondientes a cada corpus diferente."
    website
    github="https://github.com/josecannete/spanish-corpora"
    paper
    hf_dataset_name="large_spanish_corpus" 
    hf_contributor_handle="lewtun"
/>

---

<ResourceItem
    name="Mucho Cine"
    :tags="['clasificaci칩n de sentimientos']"
    description="El conjunto de datos de rese침as de Muchocine contiene 3.872 rese침as de pel칤culas en espa침ol, cada una de ellas con un breve resumen y una calificaci칩n en una escala de 1 a 5."
    website="http://www.lsi.us.es/~fermin/index.php/Datasets"
    github
    paper
    hf_dataset_name="muchocine" 
    hf_contributor_handle="mapmeld"
/>

---

<ResourceItem
    name="Spanish Billion Words"
    :tags="['modelado del lenguaje', 'pre-entrenamiento']"
    description="Spanish Billion Words es un corpus no anotado de casi 1.500 millones de palabras, compuesto por diferentes recursos online."
    website="https://crscardellino.github.io/SBWCE/"
    github
    paper
    hf_dataset_name="spanish_billion_words" 
    hf_contributor_handle="mariagrandury"
/>

---

<ResourceItem
    name="WikiCorpus"
    :tags="['modelado del lenguaje', 'POS (Part of Speech)']"
    description="El Wikicorpus es un corpus triling칲e (catal치n, espa침ol, ingl칠s) que contiene grandes partes de la Wikipedia de 2006 y que ha sido enriquecido autom치ticamente con informaci칩n ling칲칤stica. En su versi칩n actual, contiene m치s de 750 millones de palabras."
    website="https://www.cs.upc.edu/~nlp/wikicorpus/"
    github
    paper="https://www.cs.upc.edu/~nlp/papers/reese10.pdf"
    hf_dataset_name="wikicorpus" 
    hf_contributor_handle="albertvillanova"
/>

---

<ResourceItem
    name="InfoLibros Corpus"
    :tags="['modelado del lenguaje']"
    description="El corpus InfoLibros es un corpus de 218 millones de tokens de narraciones en espa침ol extra칤das de libros gratuitos recopilados por el proyecto abierto Infolibros.org. El corpus se ha preprocesado y depurado mediante el procedimiento de Corpus-Cleaner."
    website='https://doi.org/10.5281/zenodo.7313105'
    github
    paper
    hf_dataset_name
    hf_contributor_handle
/>

---

<ResourceItem
    name="Spanish CBOW Word Embeddings in Floret"
    :tags="['modelado del lenguaje','CBOW (Continuous Bag Of Words)']"
    description="Dataset compuesto por embeddings entrenados con el corpus de la Biblioteca Nacional de Espa침a (BNE) utilizando floret."
    website='https://doi.org/10.5281/zenodo.7314098'
    github
    paper
    hf_dataset_name
    hf_contributor_handle
/>

---

<ResourceItem
    name="Biomedical Spanish CBOW Word Embeddings in Floret"
    :tags="['modelado del lenguaje','CBOW (Continuous Bag Of Words)']"
    description="Dataset compuesto por embeddings entrenados en la combinaci칩n de todos los textos presentes en el corpus biom칠dico espa침ol, que incluye datos de m칰ltiples fuentes para un total de 1100M tokens a trav칠s de 2,5M de documentos."
    website='https://doi.org/10.5281/zenodo.7314041'
    github
    paper='https://arxiv.org/abs/2109.07765'
    hf_dataset_name
    hf_contributor_handle
/>

---

<ResourceItem
    name="Spanish Biomedical Crawled Corpus"
    :tags="['modelado del lenguaje']"
    description="El mayor corpus biom칠dico y de salud en espa침ol hasta la fecha, recopilado a partir de un an치lisis web masivo de dominios de salud espa침oles en m치s de 3.000 URL. Todos los datos recopilados se han preprocesado para producir el recurso CoWeSe (Corpus Web Salud Espa침ol)."
    website='https://doi.org/10.5281/zenodo.5513237'
    github
    paper='https://arxiv.org/abs/2109.07765'
    hf_dataset_name
    hf_contributor_handle
/>

---

<ResourceItem
    name="TDX Thesis Spanish Corpus"
    :tags="['modelado del lenguaje']"
    description="El corpus TDX Thesis Spanish es un corpus de 246 millones de tokens de texto limpio en espa침ol extra칤do de tesis cient칤ficas del dominio tdx.cat, que contiene tesis abiertas publicadas por universidades catalanas. El corpus se ha preprocesado y depurado mediante el procedimiento de Corpus-Cleaner."
    website='https://doi.org/10.5281/zenodo.7313149'
    github
    paper
    hf_dataset_name
    hf_contributor_handle
/>

---

<ResourceItem
    name="CSIC Spanish Corpus"
    :tags="['modelado del lenguaje']"
    description="El corpus espa침ol de CSIC es un corpus de 146 millones de tokens de revistas cient칤ficas espa침olas del repositorio revistas.csic.es/. El corpus se ha preprocesado y depurado mediante el procedimiento de Corpus-Cleaner."
    website='https://doi.org/10.5281/zenodo.7313126'
    github
    paper
    hf_dataset_name
    hf_contributor_handle
/>

---

<ResourceItem
    name="BasCrawl"
    :tags="['modelado del lenguaje']"
    description="BasCrawl es un corpus web de 186 millones de tokens en euskera obtenido mediante el an치lisis de m치s de 12000 dominios en internet (se incluyen los dominios analizados). El corpus ha sido preprocesado y depurado siguiendo el mismo procedimiento que MarIA."
    website='https://doi.org/10.5281/zenodo.7313092'
    github
    paper
    hf_dataset_name
    hf_contributor_handle
/>

---

<ResourceItem
    name="Spanish Legal Domain Corpora"
    :tags="['modelado del lenguaje']"
    description="Dataset compuesto por una colecci칩n de textos (corpus) del 치mbito jur칤dico espa침ol."
    website='https://doi.org/10.5281/zenodo.5495529'
    github='https://github.com/PlanTL-GOB-ES/lm-legal-es'
    paper='https://arxiv.org/abs/2110.12201'
    hf_dataset_name
    hf_contributor_handle
/>

---

<ResourceItem
    name="Spanish Skip-Gram Word Embeddings in FastText"
    :tags="['modelado del lenguaje','FastText']"
    description="El corpus cuenta con m치s de 2TB de texto de alta calidad, recopilado a partir de los diferentes an치lisis web realizados por la Biblioteca Nacional de Espa침a desde 2009 hasta 2019. Dataset compuesto exclusivamente por embeddings Skip-Gram."
    website='https://doi.org/10.5281/zenodo.5046525'
    github
    paper='http://journal.sepln.org/sepln/ojs/ojs/index.php/pln/article/view/6405'
    hf_dataset_name
    hf_contributor_handle
/>

---

<ResourceItem
    name="Spanish CBOW Word Embeddings in FastText"
    :tags="['modelado del lenguaje','FastText']"
    description="Embeddings de palabras en espa침ol en FastText generados a partir del mayor corpus realizado en espa침ol hasta la fecha. El corpus cuenta con m치s de 2 TB de texto de alta calidad, recopilado a partir de los diferentes rastreos web realizados por la Biblioteca Nacional de Espa침a entre 2009 y 2019. Dataset compuesto exclusivamente por CBOW embeddings."
    website='https://doi.org/10.5281/zenodo.5044988'
    github
    paper='http://journal.sepln.org/sepln/ojs/ojs/index.php/pln/article/view/6405'
    hf_dataset_name
    hf_contributor_handle
/>

---

<ResourceItem
    name="Spanish Legal Domain Word & Sub-Word Embeddings"
    :tags="['modelado del lenguaje']"
    description="Conjunto de embeddings generados a partir del corpus compuesto de recursos jur칤dicos espa침oles mas grande hasta la fecha (9GB)."
    website='https://doi.org/10.5281/zenodo.5036147'
    github='https://github.com/PlanTL-GOB-ES/lm-legal-es'
    paper='https://arxiv.org/abs/2110.12201'
    hf_dataset_name
    hf_contributor_handle
/>

---

쮼chas en falta alguna base de datos? Te animamos a **abrir una PR** [aqu칤](https://github.com/somosnlp/somosnlp.org/edit/main/pages/recursos/open-source/datasets.md) y contribuir a la lista 游
