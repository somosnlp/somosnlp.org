---
title: Selecci√≥n de art√≠culos I (Nov 2024)
description: Selecci√≥n de art√≠culos relevantes para la comunidad hispanohablante.
date: 2024-11-12T12:00:00.000+00:00
lang: es
duration: 4min
cover: https://somosnlp.github.io/assets/images/blog/serie_articulos.jpg
author: Gonzalo Mart√≠nez, PhD
bio: Investigador de PLN @UC3M
scholar: https://scholar.google.com/citations?user=FF6Yw5QAAAAJ
---

¬°Bienvenidos al primer resumen de art√≠culos de SomosNLP! 

Sabemos que es casi imposible mantenerse al d√≠a de todos los art√≠culos cient√≠ficos que van saliendo en los idiomas de la comunidad hispanohablante, as√≠ que aqu√≠ iniciamos esta serie mensual de res√∫menes para compartir contigo una selecci√≥n de art√≠culos interesantes. Si tienes alguna sugerencia o quieres que comentemos tu trabajo, ¬°escr√≠benos a info@somosnlp.com! 

## üîç Desambiguando palabras: ¬øPueden los modelos entender nuestros dobles sentidos?

*Evaluating Contextualized Representations of (Spanish) Ambiguous Words: A New Lexical Resource and Empirical Analysis*
Enlace: https://arxiv.org/html/2406.14678v2 

Los investigadores han creado un nuevo conjunto de datos llamado SAW-C, lleno de frases en espa√±ol dise√±adas para probar si los modelos ling√º√≠sticos pueden distinguir entre diferentes sentidos de una misma palabra. Eval√∫an modelos basados en BERT y los resultados muestran que aunque capturan parte de la comprensi√≥n humana, todav√≠a no alcanzan nuestro nivel. ¬°Hay que seguir trabajando en la ambig√ºedad!

## üåê Traduciendo el quechua: Desaf√≠os y soluciones con LLMs

*Shortcomings of LLMs for Low-Resource Translation: Retrieval and Understanding are Both the Problem*
Enlace: https://arxiv.org/abs/2406.15625 

Este estudio explora como mejorar la traducci√≥n del quechua sure√±o al espa√±ol utilizando modelos de lenguaje grandes. Al agregar informaci√≥n extra como traducciones de morfemas y ejemplos paralelos, descubrieron que a√∫n hay mucho por hacer debido a las variaciones regionales y dialectales. Adem√°s, resaltan la importancia de evitar errores y estereotipos al utilizar estos modelos con lenguas ind√≠genas.

## üì∞ Reviviendo peri√≥dicos del siglo XIX con LLMs

*Historical Ink: 19th Century Latin American Spanish Newspaper Corpus with LLM OCR Correction*
Enlace: https://arxiv.org/abs/2407.12838 

Los autores presentan LatamXIX, un nuevo conjunto de datos de textos de peri√≥dicos latinoamericanos del siglo XIX. Los investigadores han utilizado LLMs para corregir errores de OCR en estos textos hist√≥ricos, preservando los "errores" ling√º√≠sticos propios de la √©poca. Una herramienta fascinante para estudiar la evoluci√≥n del espa√±ol y sus variaciones hist√≥ricas.

## ü§ñ BETO necesita clases de morfolog√≠a: Evaluando su tokenizador

*Morphological Evaluation of Subwords Vocabulary Used by BETO Language Model*
Enlace: https://arxiv.org/abs/2410.02283

Este an√°lisis se centra en el modelo de lenguaje en espa√±ol BETO y su tokenizador. Los autores investigan si el tokenizador aprende efectivamente las unidades morfol√≥gicas del espa√±ol y descubren que no es as√≠ y que trabaja con otras unidades. Identificar estos problemas puede servir para mejorar c√≥mo los modelos ling√º√≠sticos procesan nuestro idioma.

## ü©∫ Preguntas m√©dicas con argumentos: Conoce CasiMedicos-Arg

*CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures*
Enlace: https://arxiv.org/abs/2410.05235 

Se presenta CasiMedicos-Arg, el primer conjunto de datos multiling√ºe de preguntas y respuestas m√©dicas en espa√±ol anotado con estructuras argumentativas. Esto proporciona informaci√≥n sobre el razonamiento detr√°s de las respuestas y contribuye al desarrollo de sistemas de IA m√°s explicables para aplicaciones m√©dicas. ¬°Un gran avance para la salud y la tecnolog√≠a!

## üîÑ Circuitos universales: El acuerdo sujeto-verbo en ingl√©s y espa√±ol

*On the Similarity of Circuits across Languages: A Case Study on the Subject-Verb Agreement Task*
Enlace: https://arxiv.org/abs/2410.06496 

Los autores estudiaron c√≥mo los modelos de lenguaje manejan el acuerdo sujeto-verbo en ingl√©s y espa√±ol utilizando el modelo Gemma 2B. Descubrieron que los circuitos utilizados son altamente consistentes entre ambos idiomas. Este hallazgo nos ayuda a entender mejor c√≥mo los modelos procesan estructuras gramaticales en diferentes lenguas.

¬°Hasta la pr√≥xima!
